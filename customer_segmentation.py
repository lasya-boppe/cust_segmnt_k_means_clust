# -*- coding: utf-8 -*-
"""customer_segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EqGHe0oOQliIgG7LhgJ1Y8mu_GDSXcij
"""

import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns

df = pd.read_csv('/content/Mall_Customers.csv')
df.head()

df.shape

df.info()

df.describe()

df.isnull().sum()

"""since my data set is not having any null values I can directly proceed to next level , But if there is any null values present we either need to remove the row or else replace with mean value of its respective columns"""

df.duplicated().sum()

df.drop(columns = ['CustomerID'], inplace = True)

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df['Gender'] = encoder.fit_transform(df['Gender'])
df.head()

plt.figure(figsize = (10,40))
for i in range(0,4):
  plt.subplot(4,2,i+1)
  sns.histplot(df[df.columns[i]],kde = True, kde_kws = dict(cut = 3), stat = 'density')
  plt.title(df.columns[i])
plt.tight_layout()

sns.heatmap(df.corr(),annot = True)
plt.show()

"""finding the actual no of clusters using elbow method 

**finding 'k' no of clusters using 'elbow' method**
"""

df.rename(columns = {'Annual Income (k$)':'income','Spending Score (1-100)': 'score'}, inplace = True)

df_req = df[['income','score']]
df_req.head()

from sklearn.cluster import KMeans
from sklearn import metrics

K = range(1,11)
wss = []
for k in K:
  kmeans = KMeans(n_clusters = k, init = 'k-means++')
  kmeans = kmeans.fit(df_req)
  wss.append(kmeans.inertia_)

clus_data = pd.DataFrame({'clus' : K, 'wss': wss})
clus_data

sns.scatterplot(data = clus_data,marker = '+' )

!pip install metric-learn

from sklearn.metrics import silhouette_samples, silhouette_score
import numpy as np
import warnings
warnings.filterwarnings('ignore')

for i in range(2,11):
  labels = KMeans(n_clusters = i, init = 'k-means++').fit(df_req).labels_
  print('silhouette score k custer :', str(i), 'is', str(silhouette_score(df_req, labels)))

"""**5 clusters !**"""

kmeans = KMeans(5)
kmeans.fit_predict(df[['score', 'income']])
df['clusters'] = kmeans.labels_
kmeans.labels_

plt.figure(figsize = (10,10))
sns.scatterplot(x="score", y="income",hue = 'clusters', data = df)

cluster_1_df = df[df['clusters'] ==0]
cluster_1_df

cluster_2_df = df[df['clusters'] ==1]
cluster_2_df

cluster_3_df = df[df['clusters'] ==2]
cluster_3_df

cluster_4_df = df[df['clusters'] ==3]
cluster_4_df

cluster_5_df = df[df['clusters'] ==4]
cluster_5_df

sns.countplot(x = 'clusters', data = df)

for i in df:
  grid = sns.FacetGrid(df, col = 'clusters')
  grid = grid.map(plt.hist, i)
plt.show()

import joblib
joblib.dump(kmeans, "kmeans.pkl")

df.to_csv('clustered_customer_data.csv')

"""training """

df_temp = df

df_temp.head()

from sklearn.model_selection import train_test_split

x = df.drop(['clusters'], axis = 1)
y = df[['clusters']]
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.4)

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report

model = DecisionTreeClassifier(criterion = "entropy")
model.fit(x_train, y_train)
predict = model.predict(x_test)

print(metrics.confusion_matrix(y_test, predict))
print(classification_report(y_test,predict))

"""Saving decision tree model for future prediction"""

import pickle
filename = 'final_model.sav'
pickle.dump(model,open(filename, 'wb'))
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(x_test,y_test)
print(result*100, '% accuracy')

